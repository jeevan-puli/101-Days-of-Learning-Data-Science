{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f97d2f7-3ae7-4e75-99f2-182ff0f53851",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bb1d752-65da-4b40-8505-ac089946c380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe01dc49-9692-4e8d-bb4b-75bceb44b72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8af50852-6f8e-4a07-aa6f-65317cc9deec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He is a good boy. She is a good girl. boy & girl are good.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph = \"He is a good boy. She is a good girl. boy & girl are good.\"\n",
    "paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97cf822-3697-4631-96d9-9255530c39fb",
   "metadata": {},
   "source": [
    "# 2 Tokenization\n",
    "## Sentence Tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e020661f-2a88-4f0e-8f10-392cd023c52a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['He is a good boy.', 'She is a good girl.', 'boy & girl are good.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data.\n",
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0fb4c1-ed44-43ae-ab5a-05456db7c789",
   "metadata": {},
   "source": [
    "## Word tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7280d59-8724-4405-b77b-b0c57cded258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['He',\n",
       " 'is',\n",
       " 'a',\n",
       " 'good',\n",
       " 'boy',\n",
       " '.',\n",
       " 'She',\n",
       " 'is',\n",
       " 'a',\n",
       " 'good',\n",
       " 'girl',\n",
       " '.',\n",
       " 'boy',\n",
       " '&',\n",
       " 'girl',\n",
       " 'are',\n",
       " 'good',\n",
       " '.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = nltk.word_tokenize(paragraph)\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e2e2df-bafa-415a-a56b-b2d48062a8ef",
   "metadata": {},
   "source": [
    "# 3 Text Cleaning \n",
    "## 3.a Remove Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db3e4677-2537-4816-83a7-4fc100503298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['He is a good boy.', 'She is a good girl.', 'boy & girl are good.']\n",
      "['He is a good boy ', 'She is a good girl ', 'boy   girl are good ']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "corpus = []\n",
    "print(sentences)\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    rp = re.sub(\"[^a-zA-Z]\", \" \",sentences[i])\n",
    "    corpus.append(rp)\n",
    "\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36a6453-4428-4e1f-9847-ac2cdbabf8dd",
   "metadata": {},
   "source": [
    "## 3.b Stopwords in English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97298af1-cecd-4b3e-8a77-06e2f7500c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "## To see list of stop words in english\n",
    "stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8b7e733-3956-4aab-be3e-d47dc5805560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good boy', 'good girl', 'boy girl good']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "corpus = []\n",
    "#print(sentences)\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    rp = re.sub(\"[^a-zA-Z]\", \" \",sentences[i])\n",
    "    rp = rp.lower()\n",
    "    rp = rp.split()\n",
    "    rp = [word for word in rp if not word in stopwords.words(\"english\")] # list list comprehensio (just if in for loop). \n",
    "    rp = \" \".join(rp)\n",
    "    corpus.append(rp)\n",
    "\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a37929-fbac-457e-94a0-9e77dd34688f",
   "metadata": {},
   "source": [
    "## 3.c Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "057dd875-2f9f-4bc0-8e25-16b69f63ac36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'histor'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "ps.stem(\"historically\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca2997c4-1e31-4436-b099-905ae25b6751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'historically'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()\n",
    "wnl.lemmatize(\"historically\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679b13ae-d973-45e5-aa14-378236d75cd4",
   "metadata": {},
   "source": [
    "## Final ever thing together for text Cleaning (remove punctuation + Remove Stop words + Stemming / Lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "679205bc-2aa8-45fe-a379-7548d34a519f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good boy', 'good girl', 'boy girl good']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer #Stemming\n",
    "ps = PorterStemmer()\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    rp = re.sub(\"[^a-zA-Z]\", \" \",sentences[i])\n",
    "    rp = rp.lower()\n",
    "    rp = rp.split()\n",
    "    rp = [ps.stem(word) for word in rp if not word in stopwords.words(\"english\")] # list list comprehensio (just if in for loop). \n",
    "    rp = \" \".join(rp)\n",
    "    corpus.append(rp)\n",
    "\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d69453-fb1c-4d7f-abbb-57d8e68f6fa8",
   "metadata": {},
   "source": [
    "# 4 Vectorization\n",
    "count vectorizer (bag of words) --> it counts the repetion no.of words in the give sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "438a1159-23d5-4889-b318-823ded39d416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1],\n",
       "       [0, 1, 1],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "bow = cv.fit_transform(corpus).toarray()\n",
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e55bef21-400e-4826-a5c6-4c996e365367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['boy', 'girl', 'good'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfe5c5f-5853-47bd-8f43-6617dfe265f4",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorizer\n",
    "- Term Frequency(tf) = no.of times term t occurs in a document.\n",
    "- inverse document frequency(idf) is a measure of how common or rare a term is across the entire corpus of documents. so the point to note is that its common to all the documents. if the word is common and appears in many documents, the idf value(normalized) will approach 0 or else approach 1 if its rare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bce70c32-adfa-4678-8f60-d503480b9415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78980693, 0.        , 0.61335554],\n",
       "       [0.        , 0.78980693, 0.61335554],\n",
       "       [0.61980538, 0.61980538, 0.48133417]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf = TfidfVectorizer()\n",
    "tfidf = tf.fit_transform(corpus).toarray()\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1183abe1-abc7-4052-be53-8d2bdaea7658",
   "metadata": {},
   "source": [
    "# Part of speech tagging(POS tagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2062a0ed-f731-43d9-a69c-22c972fb03df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'love', 'natural', 'language', 'processing']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I love natural language processing\"\n",
    "\n",
    "words = nltk.word_tokenize(text)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95f8325a-0293-417c-ad98-df121c09d626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('love', 'VBP'),\n",
       " ('natural', 'JJ'),\n",
       " ('language', 'NN'),\n",
       " ('processing', 'NN')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "24f960f7-4bfd-41c1-8db6-18776044b64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n"
     ]
    }
   ],
   "source": [
    "# to know the full for of tags use this. \n",
    "nltk.help.upenn_tagset(\"JJ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d4c491-8ae2-46e7-9b1f-db765235d3e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
